======================================================================
Optimization Log - amdahl-project.txt
======================================================================

Baseline Benchmark:
  Metrics: {'build_s': 18.55, 'size_mb': 488.28, 'qps': 13484.1, 'p50_ms': 0.075, 'p95_ms': 0.097, 'p99_ms': 0.112, 'recall': 0.9387, 'build_time_s': 18.55, 'index_size_mb': 488.28, 'throughput': 13484.1, 'best_recall': 0.9387}
  Duration: 24.01s
  Output: HNSW Initialization: Dim=128, M=16, M0=32, efConstruction=100, MaxLevel=6, FixedNodeSize=972 bytes, NodesPerPage=4, enable_prefetch=1
[HNSW Recovery] skip_recovery=false has_existing_meta=false
[HNSW Recovery] params_match=false
[HNSW Recovery] can_reuse_storage=false
[HNSW Recovery] Allocated new metadata page 4294967297 base_pid=4294967298 total_pages=250000
[HNSW Recovery] Metadata page updated and marked valid
Caliby version: 0.1.0.dev20251225235308
====================================================================================================
HNSW BENCHMARK: Caliby vs Usearch vs Faiss
====================================================================================================

Dataset: SIFT1M (1M vectors, 128 dimensions)
Parameters: M=16, ef_construction=100, ef_search=50

Libraries enabled:
  caliby     âœ“ Enabled
  usearch    âœ— Disabled
  faiss      âœ— Disabled
âœ“ SIFT1M dataset already exists in ./sift1m

Loading SIFT1M dataset...
  Base vectors: (1000000, 128)
  Quer

Project Understanding Phase:
  LLM explored 7 files

======================================================================
Iteration 1/10
======================================================================
Step 3.1: Profiling
  Profiling complete - 3 hot functions found
  Top hot functions:
    - HNSW<hnsw_distance::SIMDAcceleratedL2>::searchLayer<false>: 79.47%
    - HNSW<hnsw_distance::SIMDAcceleratedL2>::addPoint_internal: 10.44%
    - BufferManager::prefetchPages2Level: 5.15%
  Perf report: # To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 48K of event 'cpu_core/cycles/'
# Event count (approx.): 266122358596
#
# Overhead       Samples  Command  Shared Object                           Symbol                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
# ........  ............  .......  ......................................  ..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
#
    79.47%         38198  python3  caliby.cpython-310-x86_64-linux-gnu.so  [.] HNSW<hnsw_distance::SIMDAcceleratedL2>::searchLayer<false>
            |          
             --79.38%--HNSW<hnsw_distance::SIMDAcceleratedL2>::searchLayer<false>
                       |          
                        --79.37%--HNSW<hnsw_distance::SIMDAcceleratedL2>::addPoint_internal
                                  std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>, std::__future_base::

  Identified 4 bottlenecks:
    1. HNSW<...>::searchLayer<false> (79.5% cycles)
       Root cause: Address translation overhead and OLC version checking. The assembly shows multiple calls to `GuardORelaxed::initWithArray` and TLS-based translation lookups inside the tight candidate exploration loop. Even with hit-caching, the repetition of these checks for every neighbor is costly.
    2. hnsw_distance::SIMDAcceleratedL2::compare (45.0% cycles)
       Root cause: Used inside searchLayer. While SIMD-accelerated, the use of `_mm256_loadu_ps` (unaligned load) and the lack of loop unrolling for higher dimensions on the Raptor Lake architecture (which likes wide execution) leaves performance on the table. Also, the current HNSW node layout may result in non-32-byte aligned vectors.
    3. searchLayer (Candidate Management) (15.0% cycles)
       Root cause: The use of `std::priority_queue` for top candidates and `candidate_queue` involves multiple heap property restorations per node visited. For small 'ef' values, a sorted array or a more efficient heap implementation would reduce the management overhead.
    4. BufferManager::prefetchPages2Level (5.2% cycles)
       Root cause: The manual prefetching logic in `searchLayer` is currently creating `std::vector` objects (`pages_to_prefetch`) on the fly. Re-allocating these vectors inside the search loop is significantly more expensive than the actual prefetch instruction.
  Generated 2 optimization strategies:
    1. Vectorized Loop Unrolling and FMA for Distance Calculation
       Description: Unroll the AVX L2 distance loop and utilize FMA3 instructions more effectively.
       Expected: 1.08x speedup (confidence: 90%)
       Rationale: The 13900K (Raptor Lake) has two FMA units and extremely high throughput for floating-point operations. The current `L2Sqr_AVX_16` processes 16 elements per iteration but does so with a simple depende
    2. Optimization of searchLayer Candidate Prefetching
       Description: Remove dynamic vector allocations from the prefetching path in the search hot-loop.
       Expected: 1.05x speedup (confidence: 85%)
       Rationale: The profile showed `BufferManager::prefetchPages2Level` at 5.15% but also implicated allocation overhead. Inside the search loop, `pages_to_prefetch` and `offsets_within_pages` are `std::vector` objec
  Attempting strategy: Vectorized Loop Unrolling and FMA for Distance Calculation
     Target: hnsw_distance::SIMDAcceleratedL2::compare
     Expected: 1.08x
  Applying 1 code patch(es)
     âœ… Patch 1: /home/zxjcarrot/Workspace/caliby/include/caliby/distance.hpp
     Diff:
--- a//home/zxjcarrot/Workspace/caliby/include/caliby/distance.hpp
+++ b//home/zxjcarrot/Workspace/caliby/include/caliby/distance.hpp
@@ -66,26 +66,54 @@
 // --- AVX Implementation (processes 16 elements using two 8-element chunks) ---
 static inline float
 L2Sqr_AVX_16(const float *pVect1, const float *pVect2, size_t qty) {
-    size_t qty16 = qty >> 4;
-    const float *pEnd1 = pVect1 + (qty16 << 4);
-    __m256 sum = _mm256_setzero_ps();
+    size_t qty32 = qty >> 5;
+    const float *pEnd32 = pVect1 + (qty32 << 5);
+    __m256 sum0 = _mm256_setzero_ps();
+    __m256 sum1 = _mm256_setzero_ps();
     __m256 sum2 = _mm256_setzero_ps();
-
-    while (pVect1 < pEnd1) {
+    __m256 sum3 = _mm256_setzero_ps();
+
+    while (pVect1 < pEnd32) {
+        __m256 v1_0 = _mm256_loadu_ps(pVect1);
+        __m256 v2_0 = _mm256_loadu_ps(pVect2);
+        __m256 v1_1 = _mm256_loadu_ps(pVect1 + 8);
+        __m256 v2_1 = _mm256_loadu_ps(pVect2 + 8);
+        __m256 v1_2 = _mm256_loadu_ps(pVect1 + 16
  Rebuilding project...
     âœ… Build successful
  Running tests...
     âœ… Tests passed
  Benchmarking optimized code...
     ðŸ“ˆ New metrics: {'build_s': 18.91, 'size_mb': 488.28, 'qps': 13869.6, 'p50_ms': 0.073, 'p95_ms': 0.092, 'p99_ms': 0.105, 'recall': 0.9394, 'build_time_s': 18.91, 'index_size_mb': 488.28, 'throughput': 13869.6, 'best_recall': 0.9394}
     qps: 13484.10 -> 13869.60 (+2.9%)
     âœ… Accepted: 1.03x speedup
     Applied changes:
--- a//home/zxjcarrot/Workspace/caliby/include/caliby/distance.hpp
+++ b//home/zxjcarrot/Workspace/caliby/include/caliby/distance.hpp
@@ -66,26 +66,54 @@
 // --- AVX Implementation (processes 16 elements using two 8-element chunks) ---
 static inline float
 L2Sqr_AVX_16(const float *pVect1, const float *pVect2, size_t qty) {
-    size_t qty16 = qty >> 4;
-    const float *pEnd1 = pVect1 + (qty16 << 4);
-    __m256 sum = _mm256_setzero_ps();
+    size_t qty32 = qty >> 5;
+    const float *pEnd32 = pVect1 + (qty32 << 5);
+    __m256 sum0 = _mm256_setzero_ps();
+    __m256 sum1 = _mm256_setzero_ps();
     __m256 sum2 = _mm256_setzero_ps();
-
-    while (pVect1 < pEnd1) {
+    __m256 sum3 = _mm256_setzero_ps();
+
+    while (pVect1 < pEnd32) {
+        __m256 v1_0 = _mm256_loadu_ps(pVect1);
+        __m256 v2_0 = _mm256_loadu_ps(pVect2);
+        __m256 v1_1 = _mm256_loadu_ps(pVect1 + 8);
+        __m256 v2_1 = _mm256_loadu_ps(pVect2 + 8);
+        __m256 v1_2 = _mm256_loadu_ps(pVect1 + 16);
+        __m256 v2_2 = _mm256_loadu_ps(pVect2 + 16);
+        __m256 v1_3 = _mm256_loadu_ps(pVect1 + 24);
+        __m256 v2_3 = _mm256_loadu_ps(pVect2 + 24);
+        __m256 d0 = _mm256_sub_ps(v1_0, v2_0);
+        __m256 d1 = _mm256_sub_ps(v1_1, v2_1);
+        __m256 d2 = _mm256_sub_ps(v1_2, v2_2);
+        __m256 d3 = _mm256_sub_ps(v1_3, v2_3);
+        sum0 = _mm256_fmadd_ps(d0, d0, sum0);
+        sum1 = _mm256_fmadd_ps(d1, d1, sum1);
+        sum2 = _mm256_fmadd_ps(d2, d2, sum2);
+        sum3 = _mm256_fmadd_ps(d3, d3, sum3);
+        pVect1 += 32;
+        pVect2 += 32;
+    }
+
+    size_t remaining = (qty >> 4) & 1;
+    if (remaining) {
         __m256 v1_0 = _mm256_loadu_ps(pVect1);
         __m256 v2_0 = _mm256_loadu_ps(pVect2);
         __m256 v1_1 = _mm256_loadu_ps(pVect1 + 8);
         __m256 v2_1 = _mm256_loadu_ps(pVect2 + 8);
         __m256 d0 = _mm256_sub_ps(v1_0, v2_0);
         __m256 d1 = _mm256_sub_ps(v1_1, v2_1);
-        sum = _mm256_fmadd_ps(d0, d0, sum);

