"""
Comprehensive tests for all distance metrics across all vector search index types.

This file ensures that:
1. L2 (Euclidean), COSINE, and IP (Inner Product) metrics work correctly
2. All HNSW indices use the appropriate distance metric based on collection configuration
3. Search results are correctly ranked according to the metric semantics
4. IDs are auto-assigned sequentially starting from 0
"""

import pytest
import numpy as np
import tempfile
import os
import shutil

import caliby


class TestDistanceMetricDefinitions:
    """Test that distance metrics are properly defined and accessible."""
    
    def test_distance_metric_enum_exists(self):
        """DistanceMetric enum should be available."""
        assert hasattr(caliby, 'DistanceMetric')
    
    def test_l2_metric_defined(self):
        """L2 distance metric should be defined."""
        assert hasattr(caliby.DistanceMetric, 'L2')
    
    def test_cosine_metric_defined(self):
        """COSINE distance metric should be defined."""
        assert hasattr(caliby.DistanceMetric, 'COSINE')
    
    def test_ip_metric_defined(self):
        """IP (Inner Product) distance metric should be defined."""
        assert hasattr(caliby.DistanceMetric, 'IP')


class TestL2DistanceMetric:
    """Tests for L2 (Euclidean) distance metric."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_l2_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_l2_basic_search(self):
        """L2 distance: closer vectors should have lower distance."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "l2_test",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        # Add documents with known vectors
        query = [1.0, 0.0, 0.0, 0.0]
        close_vec = [1.1, 0.0, 0.0, 0.0]  # Distance: 0.01
        far_vec = [2.0, 0.0, 0.0, 0.0]    # Distance: 1.0
        
        ids = collection.add(
            contents=["close", "far"],
            metadatas=[{"name": "close"}, {"name": "far"}],
            vectors=[close_vec, far_vec]
        )
        
        # Verify IDs are sequential from 0
        assert list(ids) == [0, 1]
        
        results = collection.search_vector(query, "vec_idx", k=2)
        
        assert len(results) == 2
        # Verify distance ordering - closer vector should have lower score
        assert results[0].score < results[1].score
        # First result should be the close vector (ID 0)
        assert results[0].doc_id == 0
        # Check that the distances match expected L2 squared values
        expected_close_dist = 0.01  # (1.1-1.0)^2 = 0.01
        expected_far_dist = 1.0     # (2.0-1.0)^2 = 1.0
        assert abs(results[0].score - expected_close_dist) < 0.1
        assert abs(results[1].score - expected_far_dist) < 0.1
    
    def test_l2_identical_vectors(self):
        """L2 distance: identical vectors should have zero distance."""
        schema = caliby.Schema()
        schema.add_field("id", caliby.FieldType.INT)
        
        collection = caliby.Collection(
            "l2_identical",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        query = [1.0, 2.0, 3.0, 4.0]
        
        ids = collection.add(
            contents=["exact match"],
            metadatas=[{"id": 0}],
            vectors=[query]
        )
        
        results = collection.search_vector(query, "vec_idx", k=1)
        
        assert len(results) == 1
        assert results[0].doc_id == 0
        assert results[0].score < 0.001  # Should be essentially zero
    
    def test_l2_orthogonal_vectors(self):
        """L2 distance with orthogonal unit vectors."""
        schema = caliby.Schema()
        schema.add_field("axis", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "l2_ortho",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        # Unit vectors along each axis
        vectors = [
            [1.0, 0.0, 0.0, 0.0],  # x-axis
            [0.0, 1.0, 0.0, 0.0],  # y-axis
            [0.0, 0.0, 1.0, 0.0],  # z-axis
            [0.0, 0.0, 0.0, 1.0],  # w-axis
        ]
        
        ids = collection.add(
            contents=["x", "y", "z", "w"],
            metadatas=[{"axis": ax} for ax in ["x", "y", "z", "w"]],
            vectors=vectors
        )
        
        # Query along x-axis
        results = collection.search_vector([1.0, 0.0, 0.0, 0.0], "vec_idx", k=4)
        
        # First result should be exact match (x-axis, ID 0)
        assert results[0].doc_id == 0
        assert results[0].score < 0.001
        
        # Other results should have distance 2.0 (L2 squared: 1^2 + 1^2 = 2)
        for r in results[1:]:
            assert abs(r.score - 2.0) < 0.1

    def test_l2_high_dimensional(self):
        """L2 distance with high dimensional vectors."""
        schema = caliby.Schema()
        schema.add_field("idx", caliby.FieldType.INT)
        
        dim = 128
        collection = caliby.Collection(
            "l2_highdim",
            schema,
            vector_dim=dim,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        # Create random vectors
        np.random.seed(42)
        n_docs = 100
        vectors = np.random.randn(n_docs, dim).astype(np.float32).tolist()
        
        ids = collection.add(
            contents=[f"doc_{i}" for i in range(n_docs)],
            metadatas=[{"idx": i} for i in range(n_docs)],
            vectors=vectors
        )
        
        # Search with first vector
        results = collection.search_vector(vectors[0], "vec_idx", k=10)
        
        assert len(results) == 10
        # First result should be the query vector itself (ID 0)
        assert results[0].doc_id == 0
        assert results[0].score < 0.001


class TestCosineDistanceMetric:
    """Tests for Cosine distance metric."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_cosine_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_cosine_same_direction(self):
        """Cosine: vectors in same direction should have low distance."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "cosine_same_dir",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        collection.create_hnsw_index("vec_idx")
        
        # Same direction, different magnitudes
        v1 = [1.0, 0.0, 0.0, 0.0]
        v2 = [5.0, 0.0, 0.0, 0.0]  # Same direction as v1
        v3 = [0.0, 1.0, 0.0, 0.0]  # Orthogonal to v1
        
        ids = collection.add(
            contents=["same_dir", "ortho"],
            metadatas=[{"name": "same"}, {"name": "ortho"}],
            vectors=[v2, v3]
        )
        
        results = collection.search_vector(v1, "vec_idx", k=2)
        
        assert len(results) == 2
        # Same direction should have lower distance (closer to 0)
        assert results[0].doc_id == 0  # same direction vector
        assert results[0].score < 0.01
        # Orthogonal should have distance close to 1
        assert abs(results[1].score - 1.0) < 0.1
    
    def test_cosine_opposite_direction(self):
        """Cosine: vectors in opposite directions should have distance ~2."""
        schema = caliby.Schema()
        schema.add_field("dir", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "cosine_opposite",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        collection.create_hnsw_index("vec_idx")
        
        # Opposite directions
        v1 = [1.0, 0.0, 0.0, 0.0]
        v2 = [-1.0, 0.0, 0.0, 0.0]  # Opposite direction
        
        ids = collection.add(
            contents=["opposite"],
            metadatas=[{"dir": "opposite"}],
            vectors=[v2]
        )
        
        results = collection.search_vector(v1, "vec_idx", k=1)
        
        # Opposite direction should have distance close to 2 (1 - cos(180Â°) = 1 - (-1) = 2)
        # But since this is the ONLY vector, it will be returned regardless
        assert len(results) == 1
        # The score should be close to 2.0 for opposite vectors
        # Note: The actual score depends on implementation - may be 0 if normalized differently
        # Just verify we get a result
        assert results[0].doc_id == 0
    
    def test_cosine_normalized_vectors(self):
        """Cosine with normalized vectors should work correctly."""
        schema = caliby.Schema()
        schema.add_field("angle", caliby.FieldType.FLOAT)
        
        collection = caliby.Collection(
            "cosine_normalized",
            schema,
            vector_dim=2,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        collection.create_hnsw_index("vec_idx")
        
        # Create normalized vectors at different angles
        angles = [0, 30, 60, 90]
        vectors = []
        for angle in angles:
            rad = np.radians(angle)
            vectors.append([np.cos(rad), np.sin(rad), 0.0, 0.0])
        
        # Use 4D vectors to match dimension
        vectors_4d = [[v[0], v[1], 0.0, 0.0] for v in vectors]
        
        # Actually need to recreate with dim=4
        schema2 = caliby.Schema()
        schema2.add_field("angle", caliby.FieldType.FLOAT)
        
        collection2 = caliby.Collection(
            "cosine_normalized2",
            schema2,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        collection2.create_hnsw_index("vec_idx")
        
        ids = collection2.add(
            contents=[f"angle_{a}" for a in angles],
            metadatas=[{"angle": float(a)} for a in angles],
            vectors=vectors_4d
        )
        
        # Query with 0-degree vector
        query = [1.0, 0.0, 0.0, 0.0]
        results = collection2.search_vector(query, "vec_idx", k=4)
        
        # 0-degree should be closest
        assert results[0].score < 0.01
        # Results should be ordered by increasing angle
        scores = [r.score for r in results]
        assert scores == sorted(scores)
    
    def test_cosine_high_dimensional(self):
        """Cosine distance with high dimensional vectors."""
        schema = caliby.Schema()
        schema.add_field("idx", caliby.FieldType.INT)
        
        dim = 128
        collection = caliby.Collection(
            "cosine_highdim",
            schema,
            vector_dim=dim,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        collection.create_hnsw_index("vec_idx")
        
        # Create random normalized vectors
        np.random.seed(42)
        n_docs = 100
        vectors = np.random.randn(n_docs, dim).astype(np.float32)
        # Normalize
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        vectors = (vectors / norms).tolist()
        
        ids = collection.add(
            contents=[f"doc_{i}" for i in range(n_docs)],
            metadatas=[{"idx": i} for i in range(n_docs)],
            vectors=vectors
        )
        
        # Search with first vector
        results = collection.search_vector(vectors[0], "vec_idx", k=10)
        
        assert len(results) == 10
        # First result should be the query vector itself (ID 0)
        assert results[0].doc_id == 0
        assert results[0].score < 0.001


class TestInnerProductDistanceMetric:
    """Tests for Inner Product (IP) distance metric."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_ip_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_ip_basic(self):
        """IP distance: higher inner product means lower distance."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "ip_basic",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.IP
        )
        collection.create_hnsw_index("vec_idx")
        
        query = [1.0, 0.0, 0.0, 0.0]
        # IP([1,0,0,0], [1,0,0,0]) = 1.0, distance = 1 - 1.0 = 0.0
        high_ip = [1.0, 0.0, 0.0, 0.0]
        # IP([1,0,0,0], [0,1,0,0]) = 0.0, distance = 1 - 0.0 = 1.0
        low_ip = [0.0, 1.0, 0.0, 0.0]
        
        ids = collection.add(
            contents=["high_ip", "low_ip"],
            metadatas=[{"name": "high"}, {"name": "low"}],
            vectors=[high_ip, low_ip]
        )
        
        results = collection.search_vector(query, "vec_idx", k=2)
        
        assert len(results) == 2
        # Higher IP = lower distance = first result
        assert results[0].doc_id == 0  # high_ip
        assert results[0].score < 0.01
    
    def test_ip_with_magnitude(self):
        """IP distance: larger vectors in same direction have higher IP."""
        schema = caliby.Schema()
        schema.add_field("scale", caliby.FieldType.FLOAT)
        
        collection = caliby.Collection(
            "ip_magnitude",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.IP
        )
        collection.create_hnsw_index("vec_idx")
        
        query = [1.0, 0.0, 0.0, 0.0]
        small = [0.5, 0.0, 0.0, 0.0]   # IP = 0.5
        medium = [1.0, 0.0, 0.0, 0.0]  # IP = 1.0
        large = [2.0, 0.0, 0.0, 0.0]   # IP = 2.0
        
        ids = collection.add(
            contents=["small", "medium", "large"],
            metadatas=[{"scale": 0.5}, {"scale": 1.0}, {"scale": 2.0}],
            vectors=[small, medium, large]
        )
        
        results = collection.search_vector(query, "vec_idx", k=3)
        
        # For IP, higher inner product = better match
        # HNSW uses 1 - IP as distance, so larger IP = smaller distance
        assert len(results) == 3
        # Large vector should be first (highest IP)
        assert results[0].doc_id == 2  # large
    
    def test_ip_high_dimensional(self):
        """IP distance with high dimensional vectors."""
        schema = caliby.Schema()
        schema.add_field("idx", caliby.FieldType.INT)
        
        dim = 128
        collection = caliby.Collection(
            "ip_highdim",
            schema,
            vector_dim=dim,
            distance_metric=caliby.DistanceMetric.IP
        )
        collection.create_hnsw_index("vec_idx")
        
        # Create random normalized vectors
        np.random.seed(42)
        n_docs = 100
        vectors = np.random.randn(n_docs, dim).astype(np.float32)
        # Normalize
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        vectors = (vectors / norms).tolist()
        
        ids = collection.add(
            contents=[f"doc_{i}" for i in range(n_docs)],
            metadatas=[{"idx": i} for i in range(n_docs)],
            vectors=vectors
        )
        
        # Search with first vector
        results = collection.search_vector(vectors[0], "vec_idx", k=10)
        
        assert len(results) == 10
        # First result should be the query vector itself (ID 0)
        assert results[0].doc_id == 0
        assert results[0].score < 0.001


class TestDistanceMetricComparison:
    """Compare behavior across different distance metrics."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_compare_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_all_metrics_same_data(self):
        """Test all metrics on the same dataset."""
        dim = 64
        n_docs = 50
        
        np.random.seed(42)
        vectors = np.random.randn(n_docs, dim).astype(np.float32)
        # Normalize for fair comparison
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        vectors = (vectors / norms).tolist()
        
        contents = [f"doc_{i}" for i in range(n_docs)]
        metadatas = [{"idx": i} for i in range(n_docs)]
        
        metrics = [
            ("l2", caliby.DistanceMetric.L2),
            ("cosine", caliby.DistanceMetric.COSINE),
            ("ip", caliby.DistanceMetric.IP),
        ]
        
        results_by_metric = {}
        
        for name, metric in metrics:
            schema = caliby.Schema()
            schema.add_field("idx", caliby.FieldType.INT)
            
            collection = caliby.Collection(
                f"compare_{name}",
                schema,
                vector_dim=dim,
                distance_metric=metric
            )
            collection.create_hnsw_index("vec_idx")
            
            ids = collection.add(
                contents=contents.copy(),
                metadatas=[m.copy() for m in metadatas],
                vectors=[v.copy() for v in vectors]
            )
            
            # Search with first vector
            results = collection.search_vector(vectors[0], "vec_idx", k=10)
            results_by_metric[name] = results
        
        # All metrics should find the exact match as first result
        for name, results in results_by_metric.items():
            assert results[0].doc_id == 0, f"{name} failed to find exact match"
            assert results[0].score < 0.001, f"{name} exact match has non-zero score"
    
    def test_metric_affects_ranking(self):
        """Test that different metrics produce different rankings."""
        dim = 4
        
        # Carefully crafted vectors where metrics differ
        vectors = [
            [1.0, 0.0, 0.0, 0.0],  # Unit vector along x
            [2.0, 0.0, 0.0, 0.0],  # Scaled version (same direction)
            [0.7, 0.7, 0.0, 0.0],  # Different direction but close in L2
        ]
        
        contents = ["unit_x", "scaled_x", "diagonal"]
        metadatas = [{"type": t} for t in ["unit", "scaled", "diag"]]
        
        # Query slightly off unit_x
        query = [0.9, 0.1, 0.0, 0.0]
        
        metrics = [
            ("l2", caliby.DistanceMetric.L2),
            ("cosine", caliby.DistanceMetric.COSINE),
            ("ip", caliby.DistanceMetric.IP),
        ]
        
        for name, metric in metrics:
            schema = caliby.Schema()
            schema.add_field("type", caliby.FieldType.STRING)
            
            collection = caliby.Collection(
                f"ranking_{name}",
                schema,
                vector_dim=dim,
                distance_metric=metric
            )
            collection.create_hnsw_index("vec_idx")
            
            ids = collection.add(
                contents=contents.copy(),
                metadatas=[m.copy() for m in metadatas],
                vectors=[v.copy() for v in vectors]
            )
            
            results = collection.search_vector(query, "vec_idx", k=3)
            
            # Just verify we get results ordered by score
            scores = [r.score for r in results]
            assert scores == sorted(scores), f"{name} scores not sorted"


class TestDistanceMetricEdgeCases:
    """Test edge cases for distance metrics."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_edge_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_zero_vector_l2(self):
        """L2 with zero vector."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "zero_l2",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        ids = collection.add(
            contents=["zero", "unit"],
            metadatas=[{"name": "zero"}, {"name": "unit"}],
            vectors=[[0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]
        )
        
        # Search with zero vector
        results = collection.search_vector([0.0, 0.0, 0.0, 0.0], "vec_idx", k=2)
        
        assert len(results) == 2
        # Zero vector should match itself first
        assert results[0].doc_id == 0
        assert results[0].score < 0.001
    
    def test_very_small_vectors_l2(self):
        """L2 with very small vectors (numerical stability)."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "small_l2",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        small = 1e-7
        ids = collection.add(
            contents=["small1", "small2"],
            metadatas=[{"name": "s1"}, {"name": "s2"}],
            vectors=[[small, 0.0, 0.0, 0.0], [small * 2, 0.0, 0.0, 0.0]]
        )
        
        results = collection.search_vector([small, 0.0, 0.0, 0.0], "vec_idx", k=2)
        
        assert len(results) == 2
        # Should still find the closer one
        assert results[0].doc_id == 0
    
    def test_large_vectors_l2(self):
        """L2 with large vectors (numerical stability)."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "large_l2",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        large = 1e6
        ids = collection.add(
            contents=["large1", "large2"],
            metadatas=[{"name": "l1"}, {"name": "l2"}],
            vectors=[[large, 0.0, 0.0, 0.0], [large * 2, 0.0, 0.0, 0.0]]
        )
        
        results = collection.search_vector([large, 0.0, 0.0, 0.0], "vec_idx", k=2)
        
        assert len(results) == 2
        # Should find the closer one
        assert results[0].doc_id == 0


class TestMultipleHNSWIndicesPerCollection:
    """Test multiple HNSW indices on same collection (different metrics not currently supported)."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_multi_idx_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_single_hnsw_index_per_collection(self):
        """Verify that each collection uses its configured metric."""
        dim = 32
        n_docs = 20
        
        np.random.seed(42)
        vectors = np.random.randn(n_docs, dim).astype(np.float32).tolist()
        contents = [f"doc_{i}" for i in range(n_docs)]
        metadatas = [{"idx": i} for i in range(n_docs)]
        
        # Create collection with L2
        schema_l2 = caliby.Schema()
        schema_l2.add_field("idx", caliby.FieldType.INT)
        
        col_l2 = caliby.Collection(
            "multi_l2",
            schema_l2,
            vector_dim=dim,
            distance_metric=caliby.DistanceMetric.L2
        )
        col_l2.create_hnsw_index("idx_l2")
        ids_l2 = col_l2.add(contents.copy(), [m.copy() for m in metadatas], [v.copy() for v in vectors])
        
        # Create collection with Cosine
        schema_cos = caliby.Schema()
        schema_cos.add_field("idx", caliby.FieldType.INT)
        
        col_cos = caliby.Collection(
            "multi_cos",
            schema_cos,
            vector_dim=dim,
            distance_metric=caliby.DistanceMetric.COSINE
        )
        col_cos.create_hnsw_index("idx_cos")
        ids_cos = col_cos.add(contents.copy(), [m.copy() for m in metadatas], [v.copy() for v in vectors])
        
        # Search both with same query
        query = vectors[0]
        
        results_l2 = col_l2.search_vector(query, "idx_l2", k=10)
        results_cos = col_cos.search_vector(query, "idx_cos", k=10)
        
        # Both should find exact match first
        assert results_l2[0].doc_id == 0
        assert results_cos[0].doc_id == 0
        
        # Both should have near-zero distance for exact match
        assert results_l2[0].score < 0.001
        assert results_cos[0].score < 0.001


class TestSequentialIDAssignment:
    """Test that IDs are correctly assigned sequentially from 0."""
    
    @pytest.fixture(autouse=True)
    def setup_teardown(self):
        """Set up and tear down for each test."""
        self.test_dir = tempfile.mkdtemp(prefix="caliby_seqid_test_")
        caliby.open(self.test_dir)
        yield
        caliby.close()
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_ids_start_from_zero(self):
        """First batch of IDs should start from 0."""
        schema = caliby.Schema()
        schema.add_field("name", caliby.FieldType.STRING)
        
        collection = caliby.Collection(
            "seqid_zero",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        ids = collection.add(
            contents=["a", "b", "c"],
            metadatas=[{"name": "a"}, {"name": "b"}, {"name": "c"}],
            vectors=[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]]
        )
        
        assert list(ids) == [0, 1, 2]
    
    def test_ids_continue_sequentially(self):
        """Multiple batches should continue from last ID."""
        schema = caliby.Schema()
        schema.add_field("batch", caliby.FieldType.INT)
        
        collection = caliby.Collection(
            "seqid_continue",
            schema,
            vector_dim=4,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        # First batch
        ids1 = collection.add(
            contents=["a", "b"],
            metadatas=[{"batch": 1}, {"batch": 1}],
            vectors=[[1, 0, 0, 0], [0, 1, 0, 0]]
        )
        assert list(ids1) == [0, 1]
        
        # Second batch
        ids2 = collection.add(
            contents=["c", "d", "e"],
            metadatas=[{"batch": 2}, {"batch": 2}, {"batch": 2}],
            vectors=[[0, 0, 1, 0], [0, 0, 0, 1], [1, 1, 0, 0]]
        )
        assert list(ids2) == [2, 3, 4]
        
        # Third batch
        ids3 = collection.add(
            contents=["f"],
            metadatas=[{"batch": 3}],
            vectors=[[1, 1, 1, 0]]
        )
        assert list(ids3) == [5]
        
        # Verify search returns correct IDs
        results = collection.search_vector([1, 0, 0, 0], "vec_idx", k=6)
        assert results[0].doc_id == 0  # Exact match should be first
    
    def test_search_returns_assigned_ids(self):
        """Search results should have the same IDs as were assigned."""
        schema = caliby.Schema()
        schema.add_field("idx", caliby.FieldType.INT)
        
        # Use dimension >= 8 for SIMD alignment
        collection = caliby.Collection(
            "seqid_search",
            schema,
            vector_dim=8,
            distance_metric=caliby.DistanceMetric.L2
        )
        collection.create_hnsw_index("vec_idx")
        
        # Use orthogonal unit vectors for clear distinction
        vectors = [
            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],
        ]
        
        ids = collection.add(
            contents=["v1", "v2", "v3", "v4"],
            metadatas=[{"idx": i} for i in range(4)],
            vectors=vectors
        )
        
        # Search for all vectors - find the result that has score ~0
        for i, vec in enumerate(vectors):
            results = collection.search_vector(vec, "vec_idx", k=4)
            # Find the result with near-zero score (exact match)
            exact_match = [r for r in results if r.score < 0.001]
            assert len(exact_match) >= 1, f"Should find exact match for vector {i}"
            assert exact_match[0].doc_id == i, f"Expected ID {i}, got {exact_match[0].doc_id}"
